# Backend Architecture Audit Report

**Date:** February 2026  
**Auditor:** AI Solution Architect  
**Project:** Upwork Proposal Generator  

---

## Executive Summary

The codebase has grown organically through reactive feature additions, resulting in:
- **~12,000+ lines of Python** in the backend
- **Significant code duplication** across modules
- **728 lines of unused production code** (`proposal_generator.py`)
- **Single-tenant architecture** hardcoded
- **No clear domain boundaries**

This audit identifies cleanup targets and provides a redesign path for multi-tenant support.

---

## Code Size Analysis

| File | Lines | Status |
|------|-------|--------|
| `db.py` | 1,390 | âš ï¸ TOO LARGE - needs splitting |
| `prompt_engine.py` | 1,347 | âš ï¸ Over-engineered |
| `job_data_processor.py` | 1,075 | âš ï¸ Large but necessary |
| `hook_strategy.py` | 946 | âš ï¸ Could simplify |
| `job_data_ingestion.py` | 911 | Route file |
| `metadata_extractor.py` | 910 | âš ï¸ Duplicates logic |
| `retrieval_pipeline.py` | 882 | Core retrieval |
| `openai_service.py` | 875 | External API wrapper |
| `proposals.py` | 837 | Route file |
| `proposal_generator.py` | 728 | âŒ **UNUSED IN PRODUCTION** |
| `advanced_chunker.py` | 619 | New chunking strategy |
| `pinecone_service.py` | 458 | Vector DB service |
| `job_data_schema.py` | 472 | Pydantic models |

**Total: ~12,470 lines**

---

## Critical Issues Found

### 1. Dead/Unused Code âŒ â†’ âœ… RESOLVED

#### `proposal_generator.py` (728 lines) - ~~COMPLETELY UNUSED~~ **DELETED**

**Status:** âœ… Already deleted - file no longer exists.

**Why it was deleted:**
- Never imported in production routes (`app/routes/proposals.py`)
- Only imported in test files (which have been fixed to skip the deprecated tests)
- All proposal generation is done inline in `proposals.py` using `RetrievalPipeline + PromptEngine + OpenAIService`
- 728 lines of code that duplicated existing functionality

**Test files updated:**
- `test_proposal_generation.py` - removed dead import
- `test_geration_retrieval.py` - added pytest.skip to tests using deleted class

---

### 2. Code Duplication ğŸ”„

#### A. AI/ML Keywords (Duplicated in 2 files)

**Location 1:** `retrieval_pipeline.py` (line 63)
```python
AI_ML_KEYWORDS = [
    "openai", "gpt", "gpt-4", "chatgpt", "claude", ...
]
```

**Location 2:** `hook_strategy.py` (line 211)
```python
AI_ML_KEYWORDS = [
    "langchain", "llamaindex", "rag", "retrieval", ...
]
```

**Problem:** Different partial lists, no single source of truth.

---

#### B. Pain Point Detection (Duplicated in 2 files)

**Location 1:** `prompt_engine.py` (line 134)
```python
PAIN_POINT_INDICATORS = {
    "frustration": ["frustrated", "struggling", ...],
    "urgency": ["urgent", "asap", "immediately", ...],
    ...
}
```

**Location 2:** `hook_strategy.py` (line 450)
```python
def _extract_pain_points(self, text: str) -> List[str]:
    # Parallel implementation
```

**Problem:** Same concept, different implementations.

---

#### C. Industry Detection (3 different implementations!)

| Location | Method |
|----------|--------|
| `metadata_extractor.py:456` | `detect_industry_with_context()` |
| `openai_service.py:762` | `detect_industry_and_intent()` |
| `retrieval_pipeline.py` | `_detect_platform()` (related) |

**Problem:** Three ways to detect the same thing.

---

#### D. Urgency Detection (Duplicated)

**Location 1:** `prompt_engine.py:190` - `detect_urgency_level()`  
**Location 2:** `hook_strategy.py:180` - `URGENCY_PATTERNS`

---

### 3. Over-Engineered Components ğŸ”§

#### A. Chunking System Evolution

The chunking went through 3 generations:
1. **v1:** Basic chunking (now deprecated methods in `data_chunker.py`)
2. **v2:** 4-chunk strategy (transitional)
3. **v3:** 5-layer semantic chunking (`advanced_chunker.py`)

**Current state:**
```
data_chunker.py (120 lines)
    â””â”€â”€ Just a wrapper â†’ calls advanced_chunker.py

advanced_chunker.py (619 lines)
    â””â”€â”€ Actual implementation
```

**Problem:** `data_chunker.py` is a pass-through wrapper kept for "backward compatibility" that's not needed.

---

#### B. `db.py` is a God Object (1,390 lines)

This single file handles:
- MongoDB connection management
- 13 different collections
- CRUD for all entities
- Analytics queries
- Caching logic
- Admin key management
- Activity logging

**Should be split into:**
- `db/connection.py` - Connection management
- `repositories/training_data.py`
- `repositories/proposals.py`
- `repositories/analytics.py`
- `repositories/admin.py`

---

#### C. `prompt_engine.py` (1,347 lines)

Contains:
- Style instructions (~100 lines)
- Tone instructions (~50 lines)
- Pain point indicators (~100 lines)
- Urgency detection (~100 lines)
- Empathy responses (~100 lines)
- Hook generation (~200 lines) - duplicates `hook_strategy.py`
- Prompt building (~400 lines)
- Quality scoring (~150 lines)
- Constants that should be in config

---

### 4. Single-Tenant Hardcoding ğŸ”’

#### Current State

```python
# db.py line 1030
profile = self.db["user_profile"].find_one({"user_id": "default"})

# db.py line 1034
"user_id": "default",
```

**ALL data is global** - no isolation between:
- Users
- Organizations/Agencies
- API keys (only track role, not ownership)

#### Collections Affected

| Collection | Has user_id? | Has org_id? |
|------------|--------------|-------------|
| `training_data` | âŒ | âŒ |
| `chunks` | âŒ | âŒ |
| `embeddings` | âŒ | âŒ |
| `proposals` | âŒ | âŒ |
| `sent_proposals` | âŒ | âŒ |
| `feedback_data` | âŒ | âŒ |
| `skills` | âŒ | âŒ |
| `user_profile` | âœ… (hardcoded "default") | âŒ |
| `api_keys` | âŒ (only role) | âŒ |

---

## Current Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CURRENT ARCHITECTURE (MESSY)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ROUTES LAYER (Thin? NO - Fat controllers)                                  â”‚
â”‚  â”œâ”€â”€ proposals.py (837 lines) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚     Contains business logic inline instead of calling services         â”‚ â”‚
â”‚  â”‚     Duplicates what proposal_generator.py does                         â”‚ â”‚
â”‚  â”‚                                                                        â”‚ â”‚
â”‚  â””â”€â”€ job_data_ingestion.py (911 lines) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ â”‚
â”‚        Also contains business logic                                       â”‚â”‚ â”‚
â”‚                                                                          â”‚â”‚ â”‚
â”‚  UTILS LAYER (Bloated - 11 files, ~8000 lines)                           â”‚â”‚ â”‚
â”‚  â”œâ”€â”€ prompt_engine.py (1347) â†â”€â”€â”                                        â”‚â”‚ â”‚
â”‚  â”‚                              â”‚ Duplicate pain point detection         â”‚â”‚ â”‚
â”‚  â”œâ”€â”€ hook_strategy.py (946) â†â”€â”€â”€â”˜                                        â”‚â”‚ â”‚
â”‚  â”‚                                                                       â”‚â”‚ â”‚
â”‚  â”œâ”€â”€ metadata_extractor.py (910) â†â”€â”€â”                                    â”‚â”‚ â”‚
â”‚  â”‚                                  â”‚ 3 different industry detections    â”‚â”‚ â”‚
â”‚  â”œâ”€â”€ openai_service.py (875) â†â”€â”€â”€â”€â”€â”€â”˜                                    â”‚â”‚ â”‚
â”‚  â”‚                                                                       â”‚â”‚ â”‚
â”‚  â”œâ”€â”€ proposal_generator.py (728) â† UNUSED IN PRODUCTION!                 â”‚â”‚ â”‚
â”‚  â”‚                                                                       â”‚â”‚ â”‚
â”‚  â”œâ”€â”€ retrieval_pipeline.py (882) â† Duplicates AI_ML_KEYWORDS             â”‚â”‚ â”‚
â”‚  â”‚                                                                       â”‚â”‚ â”‚
â”‚  â”œâ”€â”€ data_chunker.py (120) â† Just a wrapper                              â”‚â”‚ â”‚
â”‚  â”‚     â””â”€â”€ advanced_chunker.py (619) â† Actual implementation             â”‚â”‚ â”‚
â”‚  â”‚                                                                       â”‚â”‚ â”‚
â”‚  â””â”€â”€ job_data_processor.py (1075) â† The actual orchestrator              â”‚â”‚ â”‚
â”‚                                                                          â”‚â”‚ â”‚
â”‚  DB LAYER (1 GOD FILE)                                                   â”‚â”‚ â”‚
â”‚  â””â”€â”€ db.py (1390 lines) â† Does EVERYTHING                                â”‚â”‚ â”‚
â”‚        - 13 collections                                                  â”‚â”‚ â”‚
â”‚        - All CRUD operations                                             â”‚â”‚ â”‚
â”‚        - Analytics                                                       â”‚â”‚ â”‚
â”‚        - Caching                                                         â”‚â”‚ â”‚
â”‚        - Admin functions                                                 â”˜â”‚ â”‚
â”‚                                                                           â”‚ â”‚
â”‚  NO SEPARATION OF CONCERNS                                                â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
```

---

## MongoDB Collections Audit

### Current Collections (13)

| # | Collection | Purpose | Records (approx) |
|---|------------|---------|------------------|
| 1 | `training_data` | Raw job data | Main data |
| 2 | `chunks` | Semantic chunks | 5 per job |
| 3 | `embeddings` | Embedding metadata | 1 per chunk |
| 4 | `proposals` | Historical proposals | Few |
| 5 | `sent_proposals` | Outcome tracking | User input |
| 6 | `feedback_data` | Client feedback | From images/text |
| 7 | `skills` | Skill frequency | Unique skills |
| 8 | `skill_embeddings` | Skill vectors | Unique skills |
| 9 | `embedding_cache` | Textâ†’embedding cache | Performance |
| 10 | `user_profile` | User settings | **1 (singleton!)** |
| 11 | `api_keys` | Auth keys | Few |
| 12 | `activity_log` | Audit trail | Many |
| 13 | (implicit) | `jobs` collection? | Check if exists |

### Redundancy Analysis

- `chunks` + `embeddings` could be merged (embedding stored on chunk)
- `skills` + `skill_embeddings` could be merged
- `embedding_cache` is useful but rarely hit

---

## Pinecone Usage Analysis

### Current State

- **Index:** `proposal-engine`
- **Dimension:** 3072 (text-embedding-3-large)
- **Namespace:** `proposals` (single namespace for ALL data)

### Problem

All vectors are in ONE namespace. For multi-tenant:
- Option A: Namespace per org (100 namespace limit)
- Option B: Metadata filter by `org_id`
- Option C: Hybrid

---

## Cleanup Targets (Priority Order)

### P0 - DELETE (No Risk)

| File | Lines | Action |
|------|-------|--------|
| `proposal_generator.py` | 728 | DELETE - unused in production |

### P1 - CONSOLIDATE (Medium Risk)

| Target | From | To | Lines Saved |
|--------|------|----|-------------|
| AI_ML_KEYWORDS | 2 files | `constants.py` | ~30 |
| INDUSTRY_KEYWORDS | 1 file | `constants.py` | ~50 |
| PLATFORM_KEYWORDS | 1 file | `constants.py` | ~30 |
| Pain point detection | 2 files | Single util | ~80 |
| Industry detection | 3 files | Single service | ~100 |
| Urgency detection | 2 files | Single util | ~50 |

### P2 - SIMPLIFY (Higher Risk)

| Target | Current | Proposed | Effort |
|--------|---------|----------|--------|
| `data_chunker.py` | Wrapper | Remove, use `advanced_chunker` directly | Low |
| `db.py` | God object | Split into repositories | Medium |
| `prompt_engine.py` | 1347 lines | Split into focused modules | High |

---

## Next Steps

1. **CREATE** `docs/ARCHITECTURE_REDESIGN.md` - Target architecture
2. **CREATE** GitHub issues for each cleanup task
3. **PRIORITIZE** sprints based on risk/impact
4. **IMPLEMENT** foundation before adding features

---

## Files Created by This Audit

- `docs/ARCHITECTURE_AUDIT.md` (this file)
- `docs/ARCHITECTURE_REDESIGN.md` (next)
- `docs/GITHUB_ISSUES.md` (sprint planning)
